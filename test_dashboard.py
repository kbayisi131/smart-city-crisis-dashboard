# -*- coding: utf-8 -*-
"""Test_Dashboard.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15NrbQp-qu0bVN2SWn-EZYHnbIb5vruZ6

from google.colab import drive
drive.mount('/content/drive')

zip_path = "/content/drive/Shareddrives/AggieHacks2025/Smart_City_Dataset.zip"

from zipfile import ZipFile

with ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall("smart_city_data")
"""

import streamlit as st
import pandas as pd
import geopandas as gpd
import pydeck as pdk
from shapely.geometry import Point
from streamlit_autorefresh import st_autorefresh

# Set up the Streamlit page configuration.
st.set_page_config(page_title="Smart City Crisis Dashboard", layout="wide")
st.title("Smart City Crisis Dashboard")

# ============================================================================
# Data Loading Functions with Caching
# ============================================================================

@st.cache_data
def load_cascade_data():
    # Load cascade risk data from CSV and ensure required conversions.
    df = pd.read_csv("data/cascade_via_gnn.csv")
    df['refined_cascade_risk_score'] = pd.to_numeric(df['refined_cascade_risk_score'], errors='coerce')
    df.dropna(subset=["latitude", "longitude", "refined_cascade_risk_score"], inplace=True)
    return df

@st.cache_data
def load_tweet_data():
    # Load tweets data from CSV and ensure proper parsing.
    df = pd.read_csv("data/tweets_df.csv")
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    df['trust_score'] = pd.to_numeric(df['trust_score'], errors='coerce')
    if df['final_fake_flag'].dtype == object:
        df['final_fake_flag'] = df['final_fake_flag'].str.lower() == 'true'
    df['geometry'] = df.apply(lambda row: Point(row['longitude'], row['latitude']), axis=1)
    return df

cascade_df = load_cascade_data()
tweets_df = load_tweet_data()

# ============================================================================
# Layout: Two Tabs for Different Visualizations
# ============================================================================

tabs = st.tabs(["Cascade Risk Heatmap", "Geographical Trust Overview"])

# ============================================================================
# Tab 1: Cascade Risk Heatmap with Manual Refresh Button
# ============================================================================
with tabs[0]:
    st.header("Cascade Risk Heatmap")
    st.write("This heatmap shows the spatial distribution of cascading risk scores.")

    # Manual refresh button: On click, clears the cache for cascade data and forces a rerun.
    if st.button("Refresh Heatmap Data"):
        load_cascade_data.clear()  # Clear cascade data cache.
        st.rerun()    # Rerun the app to load the updated data.

    # Create the PyDeck HeatmapLayer:
    heatmap_layer = pdk.Layer(
        "HeatmapLayer",
        data=cascade_df,
        get_position="[longitude, latitude]",
        get_weight="refined_cascade_risk_score",
        aggregation=pdk.types.String("SUM"),
        intensity=1,
        threshold=0.3,
    )

    # Set the initial view state centered on the average location in the cascade data:
    view_state = pdk.ViewState(
        longitude=cascade_df["longitude"].mean(),
        latitude=cascade_df["latitude"].mean(),
        zoom=11,
        pitch=45,
    )

    deck_map_risk = pdk.Deck(
        layers=[heatmap_layer],
        initial_view_state=view_state,
        tooltip={"text": "Risk Score: {refined_cascade_risk_score}"}
    )

    st.pydeck_chart(deck_map_risk)
    st.write("Areas with higher risk are shown in warmer colors on the heatmap.")

# ============================================================================
# Tab 2: Geographical Trust Overview with Auto-Refresh Every 3 Minutes
# ============================================================================
with tabs[1]:
    st.header("Geographical Trust Overview")
    st.write("""
    This view aggregates tweet trust scores by location, flagging regions where posts are less trustworthy. Trust is calculated on a scale of 1-3,
    weighing factors such as geospatial validity, sensor confirmation, and user behavior. Areas with lower average trust are indicated with darker points,
    reflecting potential misinformation hotspots.
    """)

    # Auto-refresh this tab every 3 minutes (180,000 milliseconds).
    st_autorefresh(interval=180000, key="trust_overview_refresh")

    # Create spatial bins by rounding lat/lon to group tweets (adjust rounding as needed):
    tweets_df['lat_bin'] = tweets_df['latitude'].round(2)
    tweets_df['lon_bin'] = tweets_df['longitude'].round(2)

    # Aggregate trust scores and tweet counts by spatial bins:
    aggregated = tweets_df.groupby(['lat_bin', 'lon_bin']).agg(
        avg_trust=('trust_score', 'mean'),
        tweet_count=('trust_score', 'count'),
        flagged_rate=('final_fake_flag', lambda x: x.mean())
    ).reset_index()
    aggregated.rename(columns={'lat_bin': 'lat', 'lon_bin': 'lon'}, inplace=True)

    st.subheader("Aggregated Data Preview")
    st.dataframe(aggregated.head(10))

    # Define a color mapping function: Lower trust scores map to red; higher trust to green.
    def trust_to_color(trust, min_val=0, max_val=4):
        norm = (trust - min_val) / (max_val - min_val)
        r = int(255 * (1 - norm))  # Red decreases as trust increases.
        g = int(255 * norm)        # Green increases as trust increases.
        b = 0
        return [r, g, b, 200]      # Alpha value of 200 for transparency.

    aggregated['fill_color'] = aggregated['avg_trust'].apply(trust_to_color)

    # Create a PyDeck ScatterplotLayer to visualize the aggregated trust data:
    scatter_layer = pdk.Layer(
        "ScatterplotLayer",
        data=aggregated,
        get_position="[lon, lat]",
        get_radius=200,  # Adjust radius as needed (in meters).
        get_fill_color="fill_color",
        pickable=True,
    )

    # Set view state centered on the aggregated data:
    view_state_trust = pdk.ViewState(
        longitude=aggregated['lon'].mean(),
        latitude=aggregated['lat'].mean(),
        zoom=11,
        pitch=0,
    )

    deck_map_trust = pdk.Deck(
        layers=[scatter_layer],
        initial_view_state=view_state_trust,
        tooltip={"text": "Avg Trust: {avg_trust}\nTweet Count: {tweet_count}\nFlagged Rate: {flagged_rate}"}
    )

    st.pydeck_chart(deck_map_trust)
    st.write("""
        In this visualization, areas with lower average trust (displayed in red) indicate regions where posts are less reliable.
        Areas in green indicate higher trust. The tooltip provides aggregated details including average trust, total tweets, and flagged rate.
        This updates every 3 minutes to reflect changing sentiments, allowing for real-time monitoring of trust dynamics across the city.
    """)